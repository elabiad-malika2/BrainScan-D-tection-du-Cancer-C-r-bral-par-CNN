import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.models import load_model
import joblib
import time
import cv2
import os
from collections import Counter
import warnings
warnings.filterwarnings('ignore')
from pathlib import Path

# Utilitaire robuste pour retrouver les fichiers m√©dias (images)
def get_asset_path(filename: str) -> str | None:
    base = Path(__file__).parent
    candidates = [
        base / filename,
        base / "assets" / filename,
        base.parent / filename,
        base.parent / "notebooks" / filename,
    ]
    for p in candidates:
        if p.exists():
            return str(p)
    return None

# Configuration de la page
st.set_page_config(
    page_title="Rapport d'analyse CNN ‚Äì D√©tection de tumeurs c√©r√©brales", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ======================
# TITRE ET INTRO
# ======================
st.title("üß† Rapport d'analyse du mod√®le CNN ‚Äì D√©tection de tumeurs c√©r√©brales")
st.markdown("""
Ce rapport pr√©sente l'analyse compl√®te du mod√®le CNN avec les vraies courbes d'entra√Ænement.
**Analyse de l'overfitting AVANT et APR√àS les corrections.**
""")

# ======================
# 1Ô∏è‚É£ DISTRIBUTION DES CLASSES
# ======================
st.header("1Ô∏è‚É£ Distribution des classes")

# Affichage de la vraie distribution
dist_img = get_asset_path("DustributionClass.png")
if dist_img:
    st.image(dist_img, caption="Distribution des classes dans le dataset", use_container_width=True)
else:
    st.warning("Image introuvable: DustributionClass.png")

st.markdown("""
**üìä Analyse de la distribution :**
- **D√©s√©quilibre initial** : La classe `notumor` est sur-repr√©sent√©e (2000 images)
- **Classes sous-repr√©sent√©es** : `glioma` (1621) et `meningioma` (1645) 
- **Impact** : Ce d√©s√©quilibre peut biaiser le mod√®le vers la classe majoritaire
- **Solution** : Data augmentation pour √©quilibrer √† 2000 images par classe
""")

# ======================
# 2Ô∏è‚É£ PROBL√àME D'OVERFITTING - AVANT CORRECTIONS
# ======================
st.header("2Ô∏è‚É£ Probl√®me d'Overfitting - AVANT les corrections")

st.subheader("üö® Courbes d'entra√Ænement avec overfitting s√©v√®re")

# Affichage des courbes d'overfitting
overfit_img = get_asset_path("LossAccOverfiting.png")
if overfit_img:
    st.image(overfit_img, caption="Courbes d'Accuracy et Loss - AVANT corrections (avec overfitting)", use_container_width=True)
else:
    st.warning("Image introuvable: LossAccOverfiting.png")

st.markdown("""
**üîç Analyse de l'overfitting (AVANT les corrections) - Bas√©e sur vos vraies courbes :**

**Courbe d'Accuracy :**
- **Train Accuracy** : Commence √† ~67% et monte de mani√®re constante jusqu'√† ~99% (surapprentissage)
- **Validation Accuracy** : Commence √† ~80%, atteint un pic √† ~90-93% vers l'√©poque 7-8, puis **stagne ou diminue l√©g√®rement** jusqu'√† ~90%
- **√âcart croissant** : Divergence claire entre train (99%) et validation (90%) - **gap de 9%**

**Courbe de Loss :**
- **Train Loss** : Commence √† ~0.6, diminue rapidement jusqu'√† ~0.0 (quasi nulle)
- **Validation Loss** : Commence √† ~0.6, diminue jusqu'√† ~0.3 vers l'√©poque 7-8, puis **augmente fortement** jusqu'√† ~0.45
- **Signal d'alarme** : L'augmentation de la validation loss apr√®s l'√©poque 7-8 indique un surapprentissage s√©v√®re

**üö® Diagnostic :** Le mod√®le m√©morise parfaitement les donn√©es d'entra√Ænement (99% accuracy, loss quasi nulle) mais perd sa capacit√© de g√©n√©ralisation sur les donn√©es de validation (90% accuracy, loss qui augmente). C'est un cas classique d'overfitting s√©v√®re.
""")

# ======================
# 3Ô∏è‚É£ SOLUTIONS IMPL√âMENT√âES
# ======================
st.header("3Ô∏è‚É£ Solutions impl√©ment√©es pour r√©duire l'overfitting")

st.markdown("""
**üõ†Ô∏è Techniques de r√©gularisation appliqu√©es :**

**1Ô∏è‚É£ Dropout Layers :**
- **Conv2D layers** : Dropout(0.25) apr√®s chaque bloc convolutionnel
- **Dense layers** : Dropout(0.5) apr√®s chaque couche dense
- **Effet** : D√©sactive al√©atoirement 25-50% des neurones pendant l'entra√Ænement

**2Ô∏è‚É£ Early Stopping :**
- **Monitor** : val_loss
- **Patience** : 5 √©poques
- **Effet** : Arr√™te l'entra√Ænement quand la validation loss n'am√©liore plus

**3Ô∏è‚É£ ModelCheckpoint :**
- **Monitor** : val_accuracy
- **Save best only** : True
- **Effet** : Sauvegarde le meilleur mod√®le (pas le dernier)

""")

# ======================
# 4Ô∏è‚É£ R√âSULTATS APR√àS CORRECTIONS
# ======================
st.header("4Ô∏è‚É£ R√©sultats apr√®s les corrections")

st.subheader("‚úÖ Courbes d'entra√Ænement APR√àS corrections")

# Affichage des courbes apr√®s corrections
fixed_img = get_asset_path("LossAcc.png")
if fixed_img:
    st.image(fixed_img, caption="Courbes d'Accuracy et Loss - APR√àS corrections (avec r√©gularisation)", use_container_width=True)
else:
    st.warning("Image introuvable: LossAcc.png")

st.markdown("""
**‚úÖ Am√©liorations observ√©es (APR√àS les corrections) :**

**Courbe d'Accuracy :**
- **Train Accuracy** : Augmente de mani√®re plus contr√¥l√©e jusqu'√† ~95%
- **Validation Accuracy** : Suit de pr√®s l'accuracy d'entra√Ænement (~92%)
- **√âcart r√©duit** : Divergence minimale entre train et validation (gap de 3% au lieu de 8%)

**Courbe de Loss :**
- **Train Loss** : Diminue de mani√®re stable jusqu'√† ~0.15
- **Validation Loss** : Diminue parall√®lement sans augmentation apr√®s l'√©poque 7-8
- **Convergence stable** : Pas de divergence entre les courbes

**üéØ R√©sultat :** Le mod√®le g√©n√©ralise mieux et √©vite le surapprentissage gr√¢ce au dropout et early stopping.
""")

# ======================
# 5Ô∏è‚É£ √âVALUATION FINALE
# ======================
st.header("5Ô∏è‚É£ √âvaluation finale du mod√®le")

st.subheader("üìà Performances sur le jeu de test")

# R√©sultats du notebook
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("Accuracy sur test", "90.38%", "0%")
with col2:
    st.metric("Loss sur test", "0.2669", "0%")
with col3:
    st.metric("Dur√©e d'entra√Ænement", "~58s/√©poque", "0%")

# Matrice de confusion
st.subheader("üß© Matrice de confusion")

# Affichage de la vraie matrice de confusion
cm_img = get_asset_path("confusion.png")
if cm_img:
    st.image(cm_img, caption="Matrice de confusion r√©elle du mod√®le", use_container_width=True)
else:
    st.warning("Image introuvable: confusion.png")

st.markdown("""
**üìä Analyse de la matrice de confusion :**

**Classes (0=glioma, 1=meningioma, 2=notumor, 3=pituitary) :**
- **Classe 0 (glioma)** : 357 corrects, 38 confusions avec classe 1, 0 avec classe 2, 5 avec classe 3
- **Classe 1 (meningioma)** : 330 corrects, 39 confusions avec classe 0, 12 avec classe 2, 19 avec classe 3  
- **Classe 2 (notumor)** : 379 corrects, 3 confusions avec classe 0, 13 avec classe 1, 5 avec classe 3
- **Classe 3 (pituitary)** : 380 corrects, 6 confusions avec classe 0, 14 avec classe 1, 0 avec classe 2

**üéØ Performance par classe :**
- **Meilleure classe** : Pituitary (380/400 = 95% de pr√©cision)
- **Classe la plus confuse** : Glioma et Meningioma se confondent souvent (38+39 erreurs)
- **Classe la plus stable** : Notumor (379/400 = 94.75% de pr√©cision)
- **Total corrects** : 357+330+379+380 = 1446/1600 = 90.38% d'accuracy globale
""")

# Rapport de classification
st.subheader("üìä Rapport de classification")
report_data = {
    'Classe': ['glioma', 'meningioma', 'notumor', 'pituitary'],
    'Precision': [0.88, 0.84, 0.97, 0.93],
    'Recall': [0.89, 0.82, 0.95, 0.95],
    'F1-score': [0.89, 0.83, 0.96, 0.94],
    'Support': [400, 400, 400, 400]
}

df_report = pd.DataFrame(report_data)
df_report = df_report.set_index('Classe')
st.dataframe(df_report.style.background_gradient(cmap='Greens', axis=1))

st.markdown("""
**üìä M√©triques globales :**
- **Accuracy globale** : 90.38%
- **F1-score moyen** : 90%
- **Macro avg** : 90%
- **Weighted avg** : 90%
""")

# ======================
# 6Ô∏è‚É£ ARCHITECTURE DU CNN
# ======================
st.header("6Ô∏è‚É£ Architecture d√©taill√©e du CNN")

st.subheader("üèóÔ∏è Structure compl√®te du mod√®le")

st.code("""
# Architecture CNN impl√©ment√©e
model = Sequential()

# 1√®re couche convolutionnelle + pooling + dropout
model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

# 2√®me couche convolutionnelle + pooling + dropout
model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

# 3√®me couche convolutionnelle + pooling + dropout
model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.4))

# Couches denses avec dropout
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(4, activation='softmax'))
""", language="python")

st.markdown("""
**üîß Analyse de l'architecture :**

**1Ô∏è‚É£ Blocs convolutionnels (3 blocs) :**
- **Bloc 1** : 32 filtres 3√ó3 ‚Üí MaxPooling 2√ó2 ‚Üí Dropout 0.25
- **Bloc 2** : 64 filtres 3√ó3 ‚Üí MaxPooling 2√ó2 ‚Üí Dropout 0.25  
- **Bloc 3** : 128 filtres 3√ó3 ‚Üí MaxPooling 2√ó2 ‚Üí Dropout 0.4

**2Ô∏è‚É£ Couches denses (3 couches) :**
- **Dense 1** : 128 neurones + ReLU + Dropout 0.5
- **Dense 2** : 64 neurones + ReLU + Dropout 0.5
- **Dense 3** : 4 neurones + Softmax (sortie)

**3Ô∏è‚É£ Strat√©gie de r√©gularisation :**
- **Dropout progressif** : 0.25 ‚Üí 0.25 ‚Üí 0.4 ‚Üí 0.5 ‚Üí 0.5
- **Augmentation des filtres** : 32 ‚Üí 64 ‚Üí 128 (extraction de features complexes)
- **R√©duction spatiale** : MaxPooling 2√ó2 apr√®s chaque bloc conv
- **Fonctions d'activation** : ReLU pour les couches cach√©es, Softmax pour la sortie

**4Ô∏è‚É£ Param√®tres totaux :**
- **Input shape** : (224, 224, 3) - Images RGB 224√ó224
- **Output** : 4 classes (glioma, meningioma, notumor, pituitary)
- **Optimiseur** : Adam avec learning rate 0.001
- **Fonction de perte** : categorical_crossentropy
""")

# ======================
# 7Ô∏è‚É£ CONCLUSION
# ======================
st.header("7Ô∏è‚É£ Conclusion et recommandations")

st.markdown("""
### üéØ **R√©sum√© des am√©liorations**

Le mod√®le CNN a √©t√© **consid√©rablement am√©lior√©** gr√¢ce √† l'impl√©mentation de techniques de r√©gularisation :

**üîß Techniques appliqu√©es :**
1. **Dropout progressif** dans toutes les couches (0.25 ‚Üí 0.5)
2. **Early Stopping** avec patience de 5 √©poques
3. **ModelCheckpoint** pour sauvegarder le meilleur mod√®le

**üìà R√©sultats obtenus :**
- **Accuracy de test** : 90.38%
- **Overfitting contr√¥l√©** : Gap train-validation r√©duit de 8% √† 3%
- **G√©n√©ralisation am√©lior√©e** : Performance stable sur donn√©es non vues
- **Entra√Ænement optimis√©** : Arr√™t automatique au meilleur moment

""")

# ======================
# SIDEBAR - INFORMATIONS TECHNIQUES
# ======================
with st.sidebar:
    st.header("üîß Informations techniques")
    
    st.subheader("üìä Dataset")
    st.write("- **Total images** : 7,023")
    st.write("- **Classes** : 4 (glioma, meningioma, notumor, pituitary)")
    st.write("- **Taille des images** : 224√ó224√ó3")
    st.write("- **Train/Test split** : 80/20")
    
    st.subheader("üèóÔ∏è Architecture")
    st.write("- **Type** : CNN s√©quentiel")
    st.write("- **Couches conv** : 3 blocs")
    st.write("- **Filtres** : 32‚Üí64‚Üí128")
    st.write("- **Dropout** : 0.25‚Üí0.5")
    
    st.subheader("‚öôÔ∏è Hyperparam√®tres")
    st.write("- **Optimiseur** : Adam")
    st.write("- **Learning rate** : 0.001")
    st.write("- **Batch size** : 32")
    st.write("- **√âpoques** : 30 (avec early stopping)")
    
    st.subheader("üìà Performances")
    st.write("- **Test Accuracy** : 90.38%")
    st.write("- **Test Loss** : 0.2669")
    st.write("- **F1-score moyen** : 90%")
    